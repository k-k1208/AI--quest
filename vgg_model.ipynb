{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_k.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNch+KpbdGnXQugu3cZklKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4aa33e559e1a42dcbd207ca7a1cd2be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bded72356694280b7720aeb05631217",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e5e24fde28841c5819d126608190d4d",
              "IPY_MODEL_2454a1209f9c4e6a81ed939c3cfe6f05"
            ]
          }
        },
        "9bded72356694280b7720aeb05631217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e5e24fde28841c5819d126608190d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc8bb676cc144f9788ed014fc7c9f52f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c18608ad60a0415d96d229ea8ad7f548"
          }
        },
        "2454a1209f9c4e6a81ed939c3cfe6f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf090d145f3044358e3ad66797f19599",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:58&lt;00:00, 9.49MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb69117379c84bcd923cee9c096b68dd"
          }
        },
        "fc8bb676cc144f9788ed014fc7c9f52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c18608ad60a0415d96d229ea8ad7f548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf090d145f3044358e3ad66797f19599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb69117379c84bcd923cee9c096b68dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-k1208/AI--quest/blob/master/vgg_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhXvHlXevwJc",
        "outputId": "d800176e-808c-4d18-fe6f-a6d30750aab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A3MEluRv_dO",
        "outputId": "7f85e692-34d1-4ad0-9aec-4caef6a0f95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/AI_QUEST\"\n",
        "%ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI_QUEST\n",
            " model_k.ipynb      \u001b[0m\u001b[01;34m'signate_AI Quest アセスメント'\u001b[0m/   \u001b[01;34mtrain\u001b[0m/\n",
            " sample_submit.tsv   \u001b[01;34mtest\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjRGOovYokvT"
      },
      "source": [
        "# パッケージのimport\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDqxBHyIslLT"
      },
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYzAjpuYsm25"
      },
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\n",
        "class ImageTransform():\n",
        "    \"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(\n",
        "                    resize, scale=(0.5, 1.0)),  # データオーギュメンテーション\n",
        "                transforms.RandomHorizontalFlip(),  # データオーギュメンテーション\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize(mean, std)  # 標準化\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(resize),  # リサイズ\n",
        "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize(mean, std)  # 標準化\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        phase : 'train' or 'val'\n",
        "            前処理のモードを指定。\n",
        "        \"\"\"\n",
        "        return self.data_transform[phase](img)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbV5RhrttaNL",
        "outputId": "91b5d44b-a191-4159-9d41-3b71e73dfd9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def make_datapath_list(phase=\"train\"):\n",
        "    \"\"\"\n",
        "    データのパスを格納したリストを作成する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    phase : 'train' or 'val'\n",
        "        訓練データか検証データかを指定する\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    path_list : list\n",
        "        データへのパスを格納したリスト\n",
        "    \"\"\"\n",
        "\n",
        "    rootpath = \"/content/drive/My Drive/AI_QUEST/\"\n",
        "    if phase == \"train\":\n",
        "      target_path = osp.join(rootpath+phase+'/**/*.jpeg')\n",
        "    elif phase == \"test\":\n",
        "      target_path = osp.join(rootpath+phase+'/**.jpeg')\n",
        "    else:\n",
        "      print(\"ファイルパス読み取り時の予期せぬエラー\")\n",
        "    print(target_path)\n",
        "    path_list = []  # ここに格納する\n",
        "\n",
        "    # globを利用してサブディレクトリまでファイルパスを取得する\n",
        "    for path in glob.glob(target_path):\n",
        "        path_list.append(path)\n",
        "\n",
        "    return path_list\n",
        "\n",
        "\n",
        "# 実行\n",
        "trainval_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"test\")\n",
        "\n",
        "trainval_list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI_QUEST/train/**/*.jpeg\n",
            "/content/drive/My Drive/AI_QUEST/test/**.jpeg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/AI_QUEST/train/regular/regular_000.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_001.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_002.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_004.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_003.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_005.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_006.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_009.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_008.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_007.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_011.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_010.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_013.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_012.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_014.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_015.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_016.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_017.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_018.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_019.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_021.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_020.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_023.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_022.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_024.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_025.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_027.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_026.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_029.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_028.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_031.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_030.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_034.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_033.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_032.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_035.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_036.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_037.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_038.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_040.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_039.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_042.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_041.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_044.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_043.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_046.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_045.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_047.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_048.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_049.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_050.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_051.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_052.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_053.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_055.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_054.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_057.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_056.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_058.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_059.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_061.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_060.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_063.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_062.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_064.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_065.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_067.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_066.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_068.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_069.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_071.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_070.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_073.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_072.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_075.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_074.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_077.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_076.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_078.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_079.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_081.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_080.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_082.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_083.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_085.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_084.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_087.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_086.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_089.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_088.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_090.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_091.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_093.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_092.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_094.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_096.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_095.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_098.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_097.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/regular/regular_099.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_001.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_000.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_002.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_003.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_005.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_004.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_007.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_006.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_009.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_008.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_011.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_010.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_013.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_012.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_014.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_015.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_017.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_018.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_016.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_019.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_021.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_020.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_022.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_024.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_023.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_026.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_025.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_028.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_027.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_030.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_029.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_032.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_031.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_035.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_033.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_034.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_036.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_037.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_038.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_039.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_040.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_041.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_042.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_043.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_044.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_046.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_045.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_048.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_047.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_050.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_049.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_051.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_052.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_054.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_053.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_056.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_055.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_058.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_057.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_060.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_059.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_061.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_062.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_063.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_064.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_065.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_066.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_068.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_067.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_070.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_071.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_069.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_073.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_072.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_074.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_076.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_075.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_077.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_078.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_080.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_079.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_082.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_081.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_083.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_084.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_087.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_085.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_086.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_088.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_089.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_090.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_091.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_092.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_093.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_094.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_095.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_096.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_098.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_097.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_100.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_099.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_102.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/potato/potato_101.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_000.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_001.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_003.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_002.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_004.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_005.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_006.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_008.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_007.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_009.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_010.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_011.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_012.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_013.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_015.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_014.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_016.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_017.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_019.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_018.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_020.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_021.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_022.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_023.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_024.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_025.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_026.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_028.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_027.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_030.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_029.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_031.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_032.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_033.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_034.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_036.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_035.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_037.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_038.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_040.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_039.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_042.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_041.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_044.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_043.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_046.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_045.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_048.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_047.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_050.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_049.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_051.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_052.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_054.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_055.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_053.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/horn/horn_056.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_000.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_001.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_002.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_003.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_005.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_004.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_006.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_009.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_008.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_007.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_011.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_010.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_012.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_013.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_015.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_014.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_016.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_017.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_019.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_018.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_022.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_021.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_020.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_023.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_024.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_026.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_025.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_027.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_028.jpeg',\n",
              " '/content/drive/My Drive/AI_QUEST/train/bridge/bridge_029.jpeg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWVlRVqCsrg2"
      },
      "source": [
        "class HymenopteraDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    アリとハチの画像のDatasetクラス。PyTorchのDatasetクラスを継承。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : リスト\n",
        "        画像のパスを格納したリスト\n",
        "    transform : object\n",
        "        前処理クラスのインスタンス\n",
        "    phase : 'train' or 'test'\n",
        "        学習か訓練かを設定する。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_list, transform=None, phase='train'):\n",
        "        self.file_list = file_list  # ファイルパスのリスト\n",
        "        self.transform = transform  # 前処理クラスのインスタンス\n",
        "        self.phase = phase  # train or valの指定\n",
        "\n",
        "    def __len__(self):\n",
        "        '''画像の枚数を返す'''\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        前処理をした画像のTensor形式のデータとラベルを取得\n",
        "        '''\n",
        "\n",
        "        # index番目の画像をロード\n",
        "        img_path = self.file_list[index]\n",
        "        img = Image.open(img_path)  # [高さ][幅][色RGB]\n",
        "\n",
        "        # 画像の前処理を実施\n",
        "        img_transformed = self.transform(\n",
        "            img, self.phase)  # torch.Size([3, 224, 224])\n",
        "\n",
        "        # 画像のラベルをファイル名から抜き出す\n",
        "        if self.phase == \"train\":\n",
        "            label = img_path[39:40]\n",
        "        elif self.phase == \"val\":\n",
        "            label = img_path[28:32]\n",
        "\n",
        "        # ラベルを数値に変更する\n",
        "        if label == \"b\" or  label == \"h\" or label == \"p\":\n",
        "            label = 0\n",
        "        elif label == \"r\":\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 'ラベルerrorやで'\n",
        "\n",
        "        return img_transformed, label\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVHQMR_03Ue4"
      },
      "source": [
        "trainval_dataset = HymenopteraDataset(\n",
        "    file_list=trainval_list, transform=ImageTransform(size, mean, std), phase='train')\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7AOFGho5brx",
        "outputId": "b10fd971-887d-4fbf-be2a-a45b5ce6cfce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "trainval_dataset[0]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1.4612, 1.4783, 1.4440,  ..., 1.3927, 1.3584, 1.3584],\n",
              "          [1.4612, 1.4612, 1.4612,  ..., 1.3584, 1.3584, 1.3413],\n",
              "          [1.4612, 1.5125, 1.4783,  ..., 1.3755, 1.3755, 1.3755],\n",
              "          ...,\n",
              "          [1.4440, 1.4098, 1.4612,  ..., 1.1358, 1.1700, 1.1872],\n",
              "          [1.4783, 1.4269, 1.4269,  ..., 1.1529, 1.1700, 1.1700],\n",
              "          [1.4440, 1.3584, 1.3584,  ..., 1.1529, 1.1872, 1.1700]],\n",
              " \n",
              "         [[1.6583, 1.6758, 1.6408,  ..., 1.5882, 1.5532, 1.5532],\n",
              "          [1.6583, 1.6583, 1.6583,  ..., 1.5532, 1.5532, 1.5357],\n",
              "          [1.6583, 1.7108, 1.6758,  ..., 1.5707, 1.5707, 1.5707],\n",
              "          ...,\n",
              "          [1.6408, 1.6057, 1.6583,  ..., 1.3606, 1.3606, 1.3782],\n",
              "          [1.6758, 1.6232, 1.6232,  ..., 1.3782, 1.3606, 1.3606],\n",
              "          [1.6583, 1.5707, 1.5707,  ..., 1.3957, 1.3782, 1.3606]],\n",
              " \n",
              "         [[1.8383, 1.8557, 1.8034,  ..., 1.7511, 1.7163, 1.7163],\n",
              "          [1.8208, 1.8208, 1.8208,  ..., 1.7163, 1.7163, 1.6988],\n",
              "          [1.8208, 1.8731, 1.8383,  ..., 1.7337, 1.7337, 1.7337],\n",
              "          ...,\n",
              "          [1.8383, 1.8034, 1.8383,  ..., 1.5071, 1.5245, 1.5594],\n",
              "          [1.8731, 1.8208, 1.8034,  ..., 1.5245, 1.5245, 1.5245],\n",
              "          [1.8557, 1.7685, 1.7511,  ..., 1.5420, 1.5420, 1.5071]]]), 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ8dwq382kAH",
        "outputId": "ee326604-2bc5-4780-84e5-68eb76f0287a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# アリとハチの画像へのファイルパスのリストを作成する\n",
        "trainval_list = make_datapath_list(phase=\"train\")\n",
        "\n",
        "# Datasetを作成する\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "trainval_dataset = HymenopteraDataset(\n",
        "    file_list=trainval_list, transform=ImageTransform(size, mean, std), phase='train')\n",
        "\n",
        "n_samples = len(trainval_dataset) # n_samples is 290\n",
        "train_size = int(len(trainval_dataset) * 0.8)  #232\n",
        "val_size = n_samples - train_size #58\n",
        "\n",
        "# shuffleしてから分割してくれる.\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoaderを作成する\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI_QUEST/train/**/*.jpeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrT1E-dPtzls",
        "outputId": "68c35362-750d-43e4-98af-e81afabb64e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "4aa33e559e1a42dcbd207ca7a1cd2be5",
            "9bded72356694280b7720aeb05631217",
            "4e5e24fde28841c5819d126608190d4d",
            "2454a1209f9c4e6a81ed939c3cfe6f05",
            "fc8bb676cc144f9788ed014fc7c9f52f",
            "c18608ad60a0415d96d229ea8ad7f548",
            "cf090d145f3044358e3ad66797f19599",
            "bb69117379c84bcd923cee9c096b68dd"
          ]
        }
      },
      "source": [
        "# 学習済みのVGG-16モデルをロード\n",
        "\n",
        "# VGG-16モデルのインスタンスを生成\n",
        "use_pretrained = True  # 学習済みのパラメータを使用\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "# VGG16の最後の出力層の出力ユニットをアリとハチの2つに付け替える\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aa33e559e1a42dcbd207ca7a1cd2be5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYGXUqz4tCL0",
        "outputId": "d3e8eb0e-5c89-4bfe-aeac-33a00642a03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# 1.損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 2.最適化手法を設定\n",
        "# ファインチューニングで学習させるパラメータを、変数params_to_updateの1～3に格納する\n",
        "\n",
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "# 学習させる層のパラメータ名を指定\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\",\n",
        "                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# パラメータごとに各リストに格納する\n",
        "for name, param in net.named_parameters():\n",
        "    if update_param_names_1[0] in name:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_1.append(param)\n",
        "        print(\"params_to_update_1に格納：\", name)\n",
        "\n",
        "    elif name in update_param_names_2:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_2.append(param)\n",
        "        print(\"params_to_update_2に格納：\", name)\n",
        "\n",
        "    elif name in update_param_names_3:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_3.append(param)\n",
        "        print(\"params_to_update_3に格納：\", name)\n",
        "\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "        print(\"勾配計算なし。学習しない：\", name)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params_to_update_1に格納： features.0.weight\n",
            "params_to_update_1に格納： features.0.bias\n",
            "params_to_update_1に格納： features.2.weight\n",
            "params_to_update_1に格納： features.2.bias\n",
            "params_to_update_1に格納： features.5.weight\n",
            "params_to_update_1に格納： features.5.bias\n",
            "params_to_update_1に格納： features.7.weight\n",
            "params_to_update_1に格納： features.7.bias\n",
            "params_to_update_1に格納： features.10.weight\n",
            "params_to_update_1に格納： features.10.bias\n",
            "params_to_update_1に格納： features.12.weight\n",
            "params_to_update_1に格納： features.12.bias\n",
            "params_to_update_1に格納： features.14.weight\n",
            "params_to_update_1に格納： features.14.bias\n",
            "params_to_update_1に格納： features.17.weight\n",
            "params_to_update_1に格納： features.17.bias\n",
            "params_to_update_1に格納： features.19.weight\n",
            "params_to_update_1に格納： features.19.bias\n",
            "params_to_update_1に格納： features.21.weight\n",
            "params_to_update_1に格納： features.21.bias\n",
            "params_to_update_1に格納： features.24.weight\n",
            "params_to_update_1に格納： features.24.bias\n",
            "params_to_update_1に格納： features.26.weight\n",
            "params_to_update_1に格納： features.26.bias\n",
            "params_to_update_1に格納： features.28.weight\n",
            "params_to_update_1に格納： features.28.bias\n",
            "params_to_update_2に格納： classifier.0.weight\n",
            "params_to_update_2に格納： classifier.0.bias\n",
            "params_to_update_2に格納： classifier.3.weight\n",
            "params_to_update_2に格納： classifier.3.bias\n",
            "params_to_update_3に格納： classifier.6.weight\n",
            "params_to_update_3に格納： classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHcLVVa9tF-T"
      },
      "source": [
        "#最適化手法の設定\n",
        "optimizer = optim.SGD([\n",
        "    {'params': params_to_update_1, 'lr': 1e-4},\n",
        "    {'params': params_to_update_2, 'lr': 5e-4},\n",
        "    {'params': params_to_update_3, 'lr': 1e-3}\n",
        "], momentum=0.9)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iza5EO0ptFt8"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # 初期設定\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # 結果の計算\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAIecdIOtFf6",
        "outputId": "d645a3f8-411c-48a2-ab9b-d39d51374fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs=7\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "Epoch 1/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:07<00:07,  7.06s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.37s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.6523 Acc: 0.6379\n",
            "Epoch 2/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 1/8 [00:07<00:53,  7.64s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:15<00:45,  7.64s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:22<00:38,  7.61s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:30<00:30,  7.60s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:38<00:22,  7.62s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:45<00:15,  7.63s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:53<00:07,  7.61s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:55<00:00,  6.91s/it]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.6612 Acc: 0.6207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:07<00:07,  7.06s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.41s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7013 Acc: 0.6034\n",
            "Epoch 3/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 1/8 [00:07<00:53,  7.69s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:15<00:46,  7.67s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:23<00:38,  7.68s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:30<00:30,  7.67s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:38<00:22,  7.66s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:45<00:15,  7.65s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:53<00:07,  7.67s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:55<00:00,  6.96s/it]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5674 Acc: 0.6767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:07<00:07,  7.01s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.36s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.5899 Acc: 0.6552\n",
            "Epoch 4/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 1/8 [00:07<00:53,  7.60s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:15<00:45,  7.59s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:22<00:37,  7.56s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:30<00:30,  7.55s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:37<00:22,  7.55s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:45<00:15,  7.54s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:52<00:07,  7.53s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:54<00:00,  6.85s/it]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5322 Acc: 0.7284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:06<00:06,  6.87s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.26s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4907 Acc: 0.7414\n",
            "Epoch 5/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 1/8 [00:07<00:53,  7.64s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:15<00:45,  7.61s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:22<00:37,  7.59s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:30<00:30,  7.58s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:37<00:22,  7.57s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:45<00:15,  7.57s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:52<00:07,  7.56s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:54<00:00,  6.87s/it]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4969 Acc: 0.7629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:06<00:06,  6.89s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.31s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.6444 Acc: 0.6379\n",
            "Epoch 6/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 1/8 [00:07<00:52,  7.52s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:15<00:45,  7.52s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:22<00:37,  7.52s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:30<00:30,  7.53s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:37<00:22,  7.53s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:45<00:15,  7.56s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:52<00:07,  7.58s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:54<00:00,  6.86s/it]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4750 Acc: 0.7845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:06<00:06,  6.98s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.32s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.5372 Acc: 0.7241\n",
            "Epoch 7/7\n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 1/8 [00:07<00:53,  7.68s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:15<00:46,  7.67s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:22<00:38,  7.67s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:30<00:30,  7.64s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:38<00:22,  7.62s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:45<00:15,  7.63s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:53<00:07,  7.62s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:55<00:00,  6.93s/it]\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4401 Acc: 0.7802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 1/2 [00:06<00:06,  6.84s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.5222 Acc: 0.7241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfyKi2_Et_hQ"
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}